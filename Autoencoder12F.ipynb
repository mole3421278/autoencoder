{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, zipfile\n",
    "import numpy as np, pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.feature_extraction import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "import tensorflow as tf\n",
    "print(tf.test.is_gpu_available())\n",
    "print(tf.test.is_built_with_cuda())\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))#using GPU GeForce GTX 1050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ComputeLB = False\n",
    "\n",
    "if ComputeLB: ROOT = 'D:\\Datasets\\GeneratedChibi'\n",
    "else: ROOT = 'D:\\Datasets\\Chibi'\n",
    "IMAGES = []\n",
    "for root, subdir, files in os.walk(ROOT):\n",
    "    for img in files:\n",
    "            IMAGES.append(os.path.join(root, img))\n",
    "print('There are',len(IMAGES),'images. Here are 10 example filesnames:')\n",
    "print(IMAGES[:10])#in IMAGES there is the full path to reach each image (it is only a list of strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('D:\\\\Datasets\\\\grayscale2'):\n",
    "    os.mkdir('D:\\\\Datasets\\\\grayscale2')\n",
    "if not os.path.exists('D:\\\\Datasets\\\\grayscale2\\\\images'):\n",
    "    os.mkdir('D:\\\\Datasets\\\\grayscale2\\\\images')\n",
    "\n",
    "    # CREATE LITTLE SCALED IMAGES\n",
    "    j=0\n",
    "    for im in IMAGES:\n",
    "        for i in range(2):\n",
    "            img = Image.open(im).convert('LA')\n",
    "            for k in range(3):\n",
    "                a = -4+k*8 #little translations\n",
    "                if i>0 :\n",
    "                    img2 = img.resize((256-16,256-16), Image.ANTIALIAS)\n",
    "                else :\n",
    "                    img2 = img.resize((256+16,256+16), Image.ANTIALIAS)\n",
    "                for k2 in range(3):\n",
    "                    j += 1\n",
    "                    b = -4+k2*8 #little translations\n",
    "                    background = Image.new('RGBA', (260, 260), (255, 255, 255, 255))\n",
    "                    background.paste(img2,(a,b))\n",
    "                    img2 = background.resize((256,256))\n",
    "                    img2.save('D:\\\\Datasets\\\\grayscale2\\\\images\\\\'+str(j)+'.png','PNG')\n",
    "        print('created 18 resized images')\n",
    "print('created all resized images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, LocallyConnected2D, LeakyReLU, Concatenate, Maximum, Minimum, Multiply, Subtract, Add\n",
    "from tensorflow.keras.layers import BatchNormalization, SpatialDropout2D, Conv2DTranspose, ZeroPadding2D, Flatten, Cropping2D, Average, Reshape\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16 #number of examples for minibatch\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255) #ImageDataGenerator is useful to load a lot of images in a progressive way\n",
    "train_batches = train_datagen.flow_from_directory('D:\\\\Datasets\\\\grayscale2\\\\', target_size = (256,256),\n",
    "         color_mode = 'grayscale', shuffle=True, class_mode='input', batch_size=BATCH_SIZE)#two classes: original and generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossAndErrorPrintingCallback(tf.keras.callbacks.Callback):\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    if batch % 200 == 0 :\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.subplot(1,3,1)\n",
    "        predx, predy = next(train_batches)\n",
    "        img = Image.fromarray( (255*predx[0]).astype('uint8').reshape((256,256)), 'L')\n",
    "        # instructions for the visualization\n",
    "        plt.title('Original')\n",
    "        plt.imshow(img)\n",
    "        # LATENT IMAGE\n",
    "        latent_img = encoder.predict(predx)\n",
    "        mx = np.max( latent_img[0] )\n",
    "        mn = np.min( latent_img[0] )\n",
    "        latent_flat = ((latent_img[0] - mn) * 255/(mx - mn)).flatten(order='F')\n",
    "        img = Image.fromarray( latent_flat[:1024].astype('uint8').reshape((16,16)), mode='L') \n",
    "    \n",
    "        # instructions for the visualization\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.title('Latent')\n",
    "        plt.xlim((-10,55))\n",
    "        plt.ylim((-10,55))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        decoded_img = autoencoder.predict(predx)\n",
    "        img = Image.fromarray( (255*decoded_img[0]).astype('uint8').reshape((256,256)), 'L')\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.title('Reconstructed')\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "  def on_test_batch_end(self, batch, logs=None):\n",
    "    print('For batch {}, loss is {:7.2f}.'.format(batch, logs['loss']))\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    print('Epoch finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16\n",
    "latent_filters = 1\n",
    "\n",
    "# ENCODER\n",
    "input_img = Input(shape=(256, 256, 1))  #1 because it is in grayscale\n",
    "x = Conv2D(16, (9,9), strides = (2,2), activation=LeakyReLU(alpha=0.2), kernel_initializer='random_normal', padding='same')(input_img)\n",
    "x = SpatialDropout2D(0.1)(x)\n",
    "x = Conv2D(32, (5,5), strides = (2,2), activation=LeakyReLU(alpha=0.2), kernel_initializer='random_normal', padding='same')(x)\n",
    "x = SpatialDropout2D(0.1)(x)\n",
    "x = Conv2D(48, (5,5), strides = (2,2), activation=LeakyReLU(alpha=0.2), kernel_initializer='random_normal', padding='same')(x)\n",
    "x = SpatialDropout2D(0.1)(x)\n",
    "x = Conv2D(64, (5,5), strides = (2,2), activation=LeakyReLU(alpha=0.2), kernel_initializer='random_normal', padding='same')(x)\n",
    "x = SpatialDropout2D(0.1)(x)\n",
    "encoded = Conv2D(latent_filters,(3,3), activation =LeakyReLU(alpha=0.2), kernel_initializer='random_normal', padding='same')(x)\n",
    "# LATENT SPACE\n",
    "latentSize = (latent_dim,latent_dim,latent_filters)\n",
    "\n",
    "# DECODER\n",
    "direct_input = Input(shape=latentSize)\n",
    "x = Conv2D(128, (1, 1), activation=LeakyReLU(alpha=0.2), kernel_initializer='random_normal', padding='same')(direct_input)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = SpatialDropout2D(0.1)(x)\n",
    "x = Conv2DTranspose(64, (3, 3), dilation_rate=(2,2), activation=LeakyReLU(alpha=0.2), kernel_initializer='random_normal', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = SpatialDropout2D(0.1)(x)\n",
    "x = Conv2DTranspose(48, (3, 3), dilation_rate=(2,2), activation=LeakyReLU(alpha=0.2), kernel_initializer='random_normal', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = SpatialDropout2D(0.1)(x)\n",
    "x = Conv2DTranspose(32, (3, 3), dilation_rate=(2,2), activation=LeakyReLU(alpha=0.2), kernel_initializer='random_normal', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = SpatialDropout2D(0.1)(x)\n",
    "x = Conv2DTranspose(16, (3, 3), dilation_rate=(2,2), activation=LeakyReLU(alpha=0.2), kernel_initializer='random_normal', padding='same')(x)#atrous convolution with dilation\n",
    "x = SpatialDropout2D(0.1)(x)\n",
    "decoded = Conv2D(1, (3, 3), kernel_initializer='random_normal', activation='linear', padding='same')(x)\n",
    "\n",
    "# COMPILE\n",
    "encoder = Model(input_img, encoded)\n",
    "decoder = Model(direct_input, decoded)\n",
    "autoencoder = Model(input_img, decoder(encoded))\n",
    "adam2 = tf.keras.optimizers.Adam(lr=0.0005)#default is 0.001\n",
    "autoencoder.compile(optimizer=adam2, loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit_generator(train_batches,\n",
    "        steps_per_epoch = train_batches.samples // BATCH_SIZE,\n",
    "        epochs = EPOCHS, verbose=1,\n",
    "          callbacks=[LossAndErrorPrintingCallback()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "\n",
    "#plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "#plt.title('model accuracy')\n",
    "#plt.ylabel('accuracy')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'validation'], loc='upper left')\n",
    "#plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = next(iter(train_batches))[0]\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    \n",
    "    # ORIGINAL IMAGE\n",
    "    orig = images[i,:,:,:].reshape((-1,256,256,1))\n",
    "    img = Image.fromarray( (255*orig).astype('uint8').reshape((256,256)), 'L')\n",
    "    # instructions for the visualization\n",
    "    plt.title('Original')\n",
    "    plt.imshow(img)\n",
    "\n",
    "    # LATENT IMAGE\n",
    "    latent_img = encoder.predict(orig)\n",
    "    mx = np.max( latent_img[0] )\n",
    "    mn = np.min( latent_img[0] )\n",
    "    latent_flat = ((latent_img[0] - mn) * 255/(mx - mn)).flatten(order='F')\n",
    "    img = Image.fromarray( latent_flat[:1024].astype('uint8').reshape((16,16)), mode='L') \n",
    "    \n",
    "    # instructions for the visualization\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('Latent')\n",
    "    plt.xlim((-10,55))\n",
    "    plt.ylim((-10,55))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "\n",
    "    # RECONSTRUCTED IMAGE\n",
    "    decoded_imgs = decoder.predict(latent_img[0].reshape((-1,latentSize[0],latentSize[1],latentSize[2])))\n",
    "    img = Image.fromarray( (255*decoded_imgs[0]).astype('uint8').reshape((256,256)), 'L')\n",
    "    #instructions for the visualization\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title('Reconstructed')\n",
    "    plt.imshow(img)\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "# PROJECT LATENT INTO 2D, AVOID DEAD RELU\n",
    "latent_img = encoder.predict(images)\n",
    "latent_img2 = latent_img.reshape((-1,latentSize[0]*latentSize[1]*latentSize[2]))\n",
    "d = 0; s = 0\n",
    "while s<0.1:\n",
    "    x = latent_img2[:,d]\n",
    "    s = np.std(x); d += 1\n",
    "s = 0\n",
    "while s<0.1:\n",
    "    y = latent_img2[:,d]\n",
    "    s = np.std(y); d += 1\n",
    "\n",
    "# CALCULATE ELLIPSOID FROM 256 IMAGES\n",
    "cov = np.cov(x, y)\n",
    "lambda_, v = np.linalg.eig(cov)\n",
    "lambda_ = np.sqrt(lambda_)\n",
    "for j in [1,2,3]:\n",
    "    ell = Ellipse(xy=(np.mean(x), np.mean(y)), width=lambda_[0]*j*2, \n",
    "            height=lambda_[1]*j*2, angle=np.rad2deg(np.arccos(v[0, 0])))\n",
    "    ell.set_facecolor('None')\n",
    "    ell.set_edgecolor('black')\n",
    "    plt.gca().add_artist(ell)\n",
    "    \n",
    "# PLOT 256 IMAGES AS DOTS IN LATENT SPACE\n",
    "plt.scatter(x,y)\n",
    "d = np.random.multivariate_normal([np.mean(x),np.mean(y)],cov,9)\n",
    "plt.scatter(d[:,0],d[:,1],color='red',s=100)#red points are the ones generated\n",
    "plt.title('Chibi Images form an Ellipsoid in Latent Space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE 100 IMAGES\n",
    "NO_IMG = 100\n",
    "images = next(iter(train_batches))[0]#train_batches is a tuple with image and class of the image (all of the same class)\n",
    "orig = np.zeros((NO_IMG,256,256,1))\n",
    "for i in range(NO_IMG//BATCH_SIZE):\n",
    "\n",
    "    #plt.figure(figsize=(15,5))\n",
    "    #plt.subplot(1,3,1)\n",
    "    \n",
    "    # ORIGINAL IMAGE\n",
    "    for j in range(BATCH_SIZE):\n",
    "        i += 1\n",
    "        orig[i,:,:,:] = images[j,:,:,:].reshape((-1,256,256,1))#images has in the first value the number of images for batch (now 16)\n",
    "    images = next(iter(train_batches))[0]\n",
    "        \n",
    "# CALCULATE ELLIPSOID FROM 100 IMAGES        \n",
    "encoded_imgs = encoder.predict(orig)\n",
    "sz = latentSize[0] * latentSize[1] * latentSize[2] \n",
    "encoded_imgs = encoded_imgs.reshape((-1,sz))#it must be squared\n",
    "print(encoded_imgs.shape)\n",
    "mm = np.mean(encoded_imgs,axis=0)\n",
    "ss = np.cov(encoded_imgs,rowvar=False)\n",
    "\n",
    "# GENERATE 9 RANDOM CHIBI IMAGES\n",
    "generated = np.random.multivariate_normal(mm,ss,9)\n",
    "generated = generated.reshape((-1,latentSize[0],latentSize[1],latentSize[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(3):#a matrix 3x3 of chibi figures\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    decoded_imgs = decoder.predict(generated[k*3].reshape((-1,latentSize[0],latentSize[1],latentSize[2])))\n",
    "    img = Image.fromarray( (255*decoded_imgs[0]).astype('uint8').reshape((256,256)),'L')\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,3,2)\n",
    "    decoded_imgs = decoder.predict(generated[k*3+1].reshape((-1,latentSize[0],latentSize[1],latentSize[2])))\n",
    "    img = Image.fromarray( (255*decoded_imgs[0]).astype('uint8').reshape((256,256)),'L')\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,3,3)\n",
    "    decoded_imgs = decoder.predict(generated[k*3+2].reshape((-1,latentSize[0],latentSize[1],latentSize[2])))\n",
    "    img = Image.fromarray( (255*decoded_imgs[0]).astype('uint8').reshape((256,256)),'L')\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISTANCE TO MOVE AWAY FROM EXISTING TRAIN IMAGES\n",
    "beta = 0.35\n",
    "# GENERATE 9 RANDOM CHIBI IMAGES\n",
    "generated = np.random.multivariate_normal(mm,ss,9)\n",
    "generated = beta*generated + (1-beta)*encoded_imgs[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(3):#a matrix 3x3 of chibi figures\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    decoded_imgs = decoder.predict(generated[k*3].reshape((-1,latentSize[0],latentSize[1],latentSize[2])))\n",
    "    img = Image.fromarray( (255*decoded_imgs[0]).astype('uint8').reshape((256,256)),'L')\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,3,2)\n",
    "    decoded_imgs = decoder.predict(generated[k*3+1].reshape((-1,latentSize[0],latentSize[1],latentSize[2])))\n",
    "    img = Image.fromarray( (255*decoded_imgs[0]).astype('uint8').reshape((256,256)),'L')\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,3,3)\n",
    "    decoded_imgs = decoder.predict(generated[k*3+2].reshape((-1,latentSize[0],latentSize[1],latentSize[2])))\n",
    "    img = Image.fromarray( (255*decoded_imgs[0]).astype('uint8').reshape((256,256)),'L')\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.2\n",
    "# GENERATE 100 RANDOM CHIBI IMAGES FOR KAGGLE\n",
    "generated = np.random.multivariate_normal(mm,ss,100)\n",
    "encoded_imgs = beta*generated + (1-beta)*encoded_imgs\n",
    "decoded_imgs = decoder.predict(encoded_imgs.reshape((-1,latentSize[0],latentSize[1],latentSize[2])))\n",
    "decoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE TO ZIP FILE NAMED IMAGES.ZIP\n",
    "z = zipfile.PyZipFile('D:\\\\Datasets\\\\grayscale\\\\generated12.zip', mode='w')\n",
    "for k in range(100):\n",
    "    img = Image.fromarray( (255*decoded_imgs[k]).astype('uint8').reshape((256,256)),'L')   \n",
    "    f = str(k)+'.png'\n",
    "    img.save(f,'PNG'); z.write(f); os.remove(f)\n",
    "    #if k % 1000==0: print(k)\n",
    "z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"D:\\\\Datasets\\\\grayscale\\\\autoencoder12.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('D:\\\\Datasets\\\\grayscale\\\\autoencoder10.h5', custom_objects={'LeakyReLU': tf.keras.layers.LeakyReLU})#because leakyrelu is customed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
